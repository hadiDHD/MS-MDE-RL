package msmderl.gui;//Generated by GuiGenie - Copyright (c) 2004 Mario Awad.
//Home Page http://guigenie.cjb.net - Check often for new versions!

import msmderl.general.GeneralMDP;
import msmderl.general.GeneralState;
import org.deeplearning4j.rl4j.learning.configuration.QLearningConfiguration;
import org.deeplearning4j.rl4j.learning.sync.qlearning.discrete.QLearningDiscreteDense;
import org.deeplearning4j.rl4j.mdp.MDP;
import org.deeplearning4j.rl4j.network.configuration.DQNDenseNetworkConfiguration;
import org.deeplearning4j.rl4j.policy.DQNPolicy;
import org.deeplearning4j.rl4j.space.DiscreteSpace;

import java.awt.*;
import java.io.File;
import java.io.IOException;
import java.io.OutputStream;
import java.io.PrintStream;
import javax.swing.*;

public class General extends JPanel {
    private JLabel jcomp1;
    private JTextField maxMircro;
    private JLabel jcomp3;
    private JTextField episodes;
    private JLabel jcomp5;
    private JTextField reward;
    private JLabel jcomp7;
    private JTextField gamma;
    private JButton train;
    private JLabel jcomp10;
    private JTextField nonMatch;
    private JLabel jcomp12;
    private JTextField match;
    private JLabel jcomp14;
    private JTextField cb_reward;
    private JLabel jcomp16;
    private JTextField cb_penalty;
    private JLabel jcomp18;
    private JTextField overfill;
    private JTextField maxNano;
    private JLabel jcomp21;
    private JLabel jcomp22;
    private JTextField maxMethod;
    private JLabel status;

    public General() {
        //construct components
        jcomp1 = new JLabel("Max Microservice Number: ");
        maxMircro = new JTextField(5);
        jcomp3 = new JLabel("Episode Number: ");
        episodes = new JTextField(5);
        jcomp5 = new JLabel("Reward Factor: ");
        reward = new JTextField(5);
        jcomp7 = new JLabel("Gamma: ");
        gamma = new JTextField(5);
        train = new JButton("Train");
        jcomp10 = new JLabel("NON_MATCH_PENALTY:");
        nonMatch = new JTextField(5);
        jcomp12 = new JLabel("MATCH_REWARD:");
        match = new JTextField(5);
        jcomp14 = new JLabel("CONTEXT_BOUND_REWARD:");
        cb_reward = new JTextField(5);
        jcomp16 = new JLabel("CONTEXT_BOUND_PENALTY:");
        cb_penalty = new JTextField(5);
        jcomp18 = new JLabel("OVERFILL_PENALTY:");
        overfill = new JTextField(5);
        maxNano = new JTextField(5);
        jcomp21 = new JLabel("Max Nanoentitiy Number:");
        jcomp22 = new JLabel("Max Method Number: ");
        maxMethod = new JTextField(5);
        status = new JLabel("");


        reward.setText("0.9");
        gamma.setText("0.1");
        nonMatch.setText("10");
        match.setText("20");
        cb_reward.setText("20");
        cb_penalty.setText("10");
        overfill.setText("5");


        train.addActionListener(e -> {
            status.setText("Please Wait...");
            train();
            status.setText("Done");
        });

        //adjust size and set layout
        setPreferredSize(new Dimension(752, 431));
        setLayout(null);

        //add components
        add(jcomp1);
        add(maxMircro);
        add(jcomp3);
        add(episodes);
        add(jcomp5);
        add(reward);
        add(jcomp7);
        add(gamma);
        add(train);
        add(jcomp10);
        add(nonMatch);
        add(jcomp12);
        add(match);
        add(jcomp14);
        add(cb_reward);
        add(jcomp16);
        add(cb_penalty);
        add(jcomp18);
        add(overfill);
        add(maxNano);
        add(jcomp21);
        add(jcomp22);
        add(maxMethod);
        add(status);

        //set component bounds (only needed by Absolute Positioning)
        jcomp1.setBounds(15, 15, 190, 25);
        maxMircro.setBounds(215, 15, 155, 25);
        jcomp3.setBounds(15, 150, 185, 25);
        episodes.setBounds(215, 150, 155, 25);
        jcomp5.setBounds(15, 190, 185, 25);
        reward.setBounds(215, 190, 155, 25);
        jcomp7.setBounds(15, 235, 185, 25);
        gamma.setBounds(215, 235, 155, 25);
        train.setBounds(330, 295, 100, 25);
        jcomp10.setBounds(400, 15, 175, 25);
        nonMatch.setBounds(585, 15, 155, 25);
        jcomp12.setBounds(400, 60, 150, 25);
        match.setBounds(585, 60, 155, 25);
        jcomp14.setBounds(400, 105, 185, 25);
        cb_reward.setBounds(585, 105, 155, 25);
        jcomp16.setBounds(400, 150, 180, 25);
        cb_penalty.setBounds(585, 150, 155, 25);
        jcomp18.setBounds(400, 190, 185, 25);
        overfill.setBounds(585, 190, 155, 25);
        maxNano.setBounds(215, 60, 155, 25);
        jcomp21.setBounds(15, 60, 185, 25);
        jcomp22.setBounds(15, 105, 195, 25);
        maxMethod.setBounds(215, 105, 155, 25);
        status.setBounds(330, 345, 100, 25);
    }

    private void train() {
        try {
            JFileChooser fileChooser = new JFileChooser();
            fileChooser.showSaveDialog(null);
            File file = fileChooser.getSelectedFile();
            QLearningConfiguration qLearningConfiguration = QLearningConfiguration.builder()
                    .maxEpochStep(Integer.MAX_VALUE)
                    .maxStep(Integer.parseInt(episodes.getText()))
                    .rewardFactor(Double.parseDouble(reward.getText()))
                    .gamma(Double.parseDouble(gamma.getText()))
                    .build();
            GeneralMDP mdp = new GeneralMDP();
            mdp.MAX_MICROSERVICE = Integer.parseInt(maxMircro.getText());
            mdp.MAX_NANO_ENTITY = Integer.parseInt(maxNano.getText());
            mdp.MAX_METHOD = Integer.parseInt(maxMethod.getText());
            mdp.MIN_MICROSERVICE = mdp.MAX_MICROSERVICE;
            mdp.NON_MATCH_PENALTY = Integer.parseInt(nonMatch.getText());
            mdp.MATCH_REWARD = Integer.parseInt(match.getText());
            mdp.CONTEXT_BOUND_REWARD = Integer.parseInt(cb_reward.getText());
            mdp.CONTEXT_BOUND_PENALTY = Integer.parseInt(cb_penalty.getText());
            mdp.OVERFILL_PENALTY = Integer.parseInt(overfill.getText());
            mdp.initGenerator();
            mdp.init();

            QLearningDiscreteDense<GeneralState> dql = defineTraining(mdp, qLearningConfiguration);
            dql.train();

            DQNPolicy<GeneralState> pol = dql.getPolicy();

            saveForFutureReuse(pol, file);

            mdp.close();
        } catch (Exception e) {
            JOptionPane.showMessageDialog(this, e.getMessage(), "Error", JOptionPane.ERROR_MESSAGE);
            e.printStackTrace();
        }
    }

    private QLearningDiscreteDense<GeneralState> defineTraining(MDP<GeneralState, Integer, DiscreteSpace> mdp, QLearningConfiguration ql) {
        return new QLearningDiscreteDense<>(mdp, DQNDenseNetworkConfiguration.builder().build(), ql);
    }

    private void saveForFutureReuse(DQNPolicy<GeneralState> pol, File file) throws IOException {
        file.mkdirs();
        file.delete();
        pol.save(file.getAbsolutePath());
    }


    public static void main(String[] args) {
        JFrame frame = new JFrame("General");
        frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);
        frame.getContentPane().add(new General());
        frame.pack();
        frame.setVisible(true);
    }

    private void updateTextArea(final String text) {
//        SwingUtilities.invokeLater(() -> textArea.append(text));
    }

    private void redirectSystemStreams() {
        OutputStream out = new OutputStream() {
            @Override
            public void write(int b) throws IOException {
                updateTextArea(String.valueOf((char) b));
            }

            @Override
            public void write(byte[] b, int off, int len) throws IOException {
                updateTextArea(new String(b, off, len));
            }

            @Override
            public void write(byte[] b) throws IOException {
                write(b, 0, b.length);
            }
        };

        System.setOut(new PrintStream(out, true));
        System.setErr(new PrintStream(out, true));
    }
}
